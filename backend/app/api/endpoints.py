from fastapi import APIRouter, UploadFile, File, HTTPException, WebSocket, WebSocketDisconnect, BackgroundTasks, Form, Body
from fastapi.responses import FileResponse
import shutil
import uuid
import os
import asyncio
import json
from typing import List, Dict
from app.config import settings
from app.service.video_llm import video_llm
from app.service.video_producer import render_final_video
from app.core.rag_engine import rag_engine

router = APIRouter()

# WebSocket Connection Manager
class ConnectionManager:
    def __init__(self):
        self.active_connections: Dict[str, WebSocket] = {}

    async def connect(self, websocket: WebSocket, client_id: str):
        await websocket.accept()
        self.active_connections[client_id] = websocket

    def disconnect(self, client_id: str):
        if client_id in self.active_connections:
            del self.active_connections[client_id]

    async def send_json(self, data: dict, client_id: str):
        if client_id in self.active_connections:
            await self.active_connections[client_id].send_json(data)

manager = ConnectionManager()

@router.websocket("/ws/{client_id}")
async def websocket_endpoint(websocket: WebSocket, client_id: str):
    await manager.connect(websocket, client_id)
    print(f"[INFO] ðŸ”Œ WebSocket è¿žæŽ¥å»ºç«‹: client_id={client_id}")
    try:
        while True:
            data = await websocket.receive_text()
            try:
                message_data = json.loads(data)
                if message_data.get("type") == "chat":
                    user_message = message_data.get("message")
                    history = message_data.get("history", [])
                    model_name = message_data.get("model", "gemini-3-pro-preview")
                    use_stream = message_data.get("stream", True)  # é»˜è®¤ä½¿ç”¨æµå¼è¾“å‡º
                    
                    print(f"[INFO] ðŸ“¨ æ”¶åˆ°èŠå¤©è¯·æ±‚ - ç”¨æˆ·: {user_message[:30]}...")
                    print(f"[INFO] ðŸ“Š æ¶ˆæ¯ç»Ÿè®¡ - åŽ†å²: {len(history)} æ¡, æ¨¡åž‹: {model_name}, æµå¼: {use_stream}")
                    
                    # å‘é€å¼€å§‹çŠ¶æ€
                    await manager.send_json({
                        "type": "chat_start",
                        "message": "AI æ­£åœ¨æ€è€ƒ..."
                    }, client_id)
                    
                    if use_stream:
                        # æµå¼è¾“å‡º
                        print(f"[INFO] ðŸŒŠ å¼€å§‹æµå¼ç”Ÿæˆå›žå¤...")
                        import time
                        import asyncio
                        stream_response = video_llm.chat(user_message, history, model_name=model_name, stream=True)
                        full_text = ""
                        chunk_count = 0
                        
                        for chunk in stream_response:
                            if hasattr(chunk, 'text') and chunk.text:
                                full_text += chunk.text
                                chunk_count += 1
                                
                                # è®°å½•æ—¶é—´æˆ³
                                timestamp = time.time()
                                print(f"[INFO] ðŸ“¡ [{timestamp}] å‘é€ç‰‡æ®µ #{chunk_count}, chunké•¿åº¦: {len(chunk.text)}, æ€»é•¿åº¦: {len(full_text)}")
                                
                                # å‘é€æµå¼ç‰‡æ®µ
                                await manager.send_json({
                                    "type": "chat_stream",
                                    "chunk": chunk.text,
                                    "full_text": full_text
                                }, client_id)
                                
                                # æ·»åŠ å»¶è¿Ÿï¼Œè®©å‰ç«¯æœ‰æ—¶é—´æ¸²æŸ“æ¯ä¸ªç‰‡æ®µï¼ˆ100msï¼‰
                                await asyncio.sleep(0.1)
                        
                        print(f"[INFO] âœ… æµå¼è¾“å‡ºå®Œæˆ - å…± {chunk_count} ä¸ªç‰‡æ®µ, æ€»é•¿åº¦: {len(full_text)} å­—ç¬¦")
                        
                        # å‘é€å®ŒæˆçŠ¶æ€
                        await manager.send_json({
                            "type": "chat_response",
                            "message": full_text,
                            "is_complete": True
                        }, client_id)
                    else:
                        # éžæµå¼è¾“å‡ºï¼ˆä¸€æ¬¡æ€§è¿”å›žï¼‰
                        print(f"[INFO] ðŸ“¦ ä½¿ç”¨éžæµå¼æ¨¡å¼...")
                        response_text = video_llm.chat(user_message, history, model_name=model_name, stream=False)
                        
                        await manager.send_json({
                            "type": "chat_response",
                            "message": response_text
                        }, client_id)
                        
            except json.JSONDecodeError:
                print(f"[ERROR] âŒ JSON è§£æžå¤±è´¥")
                pass
            except Exception as e:
                print(f"[ERROR] âŒ èŠå¤©å¤„ç†å¼‚å¸¸: {str(e)}")
                import traceback
                traceback.print_exc()
                await manager.send_json({
                    "type": "error",
                    "message": f"Chat error: {str(e)}"
                }, client_id)
    except WebSocketDisconnect:
        print(f"[INFO] ðŸ”Œ WebSocket è¿žæŽ¥æ–­å¼€: client_id={client_id}")
        manager.disconnect(client_id)

@router.post("/add_knowledge")
async def add_knowledge(file: UploadFile = File(...)):
    """ä¸Šä¼ æ–°çš„ PDF åˆ°çŸ¥è¯†åº“ (å¢žé‡æ›´æ–°)"""
    try:
        # 1. ä¿å­˜æ–‡ä»¶åˆ° data ç›®å½•
        filename = f"{uuid.uuid4()}_{file.filename}"
        file_path = os.path.join(settings.DATA_DIR, filename)
        
        with open(file_path, "wb") as buffer:
            shutil.copyfileobj(file.file, buffer)
            
        # 2. è°ƒç”¨å¼•æ“Žæ·»åŠ åˆ°å‘é‡åº“
        rag_engine.add_pdf(file_path)
        
        return {
            "status": "success", 
            "message": f"æ–‡æ¡£ '{file.filename}' å·²æˆåŠŸåŠ å…¥çŸ¥è¯†åº“ï¼Œè¯­æ–™åº“å·²æ‰©å¤§ã€‚"
        }
    except Exception as e:
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/refresh_rag")
async def refresh_rag():
    """(å¯é€‰) é‡æ–°åŠ è½½æ•°æ®åº“è¿žæŽ¥"""
    try:
        rag_engine.initialize_knowledge_base()
        return {"status": "success", "message": "çŸ¥è¯†åº“è¿žæŽ¥å·²åˆ·æ–°"}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

def process_video_task(file_path: str, session_path: str, client_id: str, loop: asyncio.AbstractEventLoop, prompt: str = None, model_name: str = "gemini-3-pro-preview"):
    try:
        def progress_callback(msg):
            asyncio.run_coroutine_threadsafe(
                manager.send_json({"type": "progress", "message": msg}, client_id),
                loop
            )

        # 1. LLM Pipeline
        progress_callback("æ­£åœ¨åˆ†æžè§†é¢‘...")
        script_data, text_analysis = video_llm.process_video_pipeline(file_path, user_prompt=prompt, progress_callback=progress_callback, model_name=model_name)
        
        # 2. Render Video
        progress_callback("æ­£åœ¨æ¸²æŸ“æœ€ç»ˆè§†é¢‘...")
        session_id = os.path.basename(session_path)
        output_filename = "final_output.mp4"
        
        # ä½¿ç”¨ asyncio.run_coroutine_threadsafe æ¥è¿è¡Œå¼‚æ­¥å‡½æ•°
        future = asyncio.run_coroutine_threadsafe(
            render_final_video(script_data, session_id),
            loop
        )
        # ç­‰å¾…è§†é¢‘æ¸²æŸ“å®Œæˆ
        future.result()
        
        progress_callback("è§†é¢‘ç”Ÿæˆå®Œæˆï¼")
        
        download_url = f"/api/download/{session_id}/{output_filename}"
        
        asyncio.run_coroutine_threadsafe(
            manager.send_json({
                "type": "complete",
                "download_url": download_url,
                "text_analysis": text_analysis
            }, client_id),
            loop
        )
        
    except Exception as e:
        import traceback
        error_msg = str(e)
        
        # é’ˆå¯¹ Edge TTS é”™è¯¯æä¾›æ›´å‹å¥½çš„æç¤º
        if "503" in error_msg or "WSServerHandshakeError" in error_msg:
            error_msg = "è¯­éŸ³åˆæˆæœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åŽé‡è¯•"
        elif "edge_tts" in error_msg.lower() or "tts" in error_msg.lower():
            error_msg = f"è¯­éŸ³ç”Ÿæˆå¤±è´¥: {error_msg}"
        else:
            error_msg = f"è§†é¢‘ç”Ÿæˆå¤±è´¥: {error_msg}"
            
        print(f"[ERROR] {error_msg}")
        traceback.print_exc()
        asyncio.run_coroutine_threadsafe(
            manager.send_json({
                "type": "error",
                "message": error_msg
            }, client_id),
            loop
        )

@router.post("/generate")
async def generate_video(
    background_tasks: BackgroundTasks,
    file: UploadFile = File(...),
    client_id: str = Form(...),
    prompt: str = Form(None),
    model: str = Form("gemini-3-pro-preview")
):
    session_id = str(uuid.uuid4())
    session_path = os.path.join(settings.TEMP_DIR, session_id)
    os.makedirs(session_path, exist_ok=True)
    
    filename = f"input_{file.filename}"
    file_path = os.path.join(session_path, filename)
    
    with open(file_path, "wb") as buffer:
        shutil.copyfileobj(file.file, buffer)
    
    loop = asyncio.get_running_loop()
    background_tasks.add_task(process_video_task, file_path, session_path, client_id, loop, prompt, model)
    
    return {"status": "processing", "session_id": session_id}

@router.post("/generate-title")
async def generate_title(request: dict = Body(...)):
    """ä¸ºå¯¹è¯ä¼šè¯ç”Ÿæˆæ™ºèƒ½æ ‡é¢˜"""
    try:
        first_message = request.get("message", "")
        model_name = request.get("model", "gemini-2.0-flash")
        
        if not first_message:
            return {"title": "æ–°å¯¹è¯"}
        
        title = video_llm.generate_session_title(first_message, model_name)
        return {"title": title}
    except Exception as e:
        print(f"[ERROR] ç”Ÿæˆæ ‡é¢˜å¤±è´¥: {e}")
        return {"title": first_message[:15] + ("..." if len(first_message) > 15 else "")}

@router.get("/download/{session_id}/{filename}")
async def download_file(session_id: str, filename: str):
    file_path = os.path.join(settings.TEMP_DIR, session_id, filename)
    if os.path.exists(file_path):
        return FileResponse(file_path)
    raise HTTPException(status_code=404, detail="File not found")